# ğŸ“ˆ Crypto Market ELT Pipeline & Dashboard

## CHECK MASTER BRANCH FOR CODE AND DOCUMENTATION
                                          -----DEEPAK GADDE

This project implements a full-stack ELT (Extract, Load, Transform) pipeline for tracking and visualizing real-time cryptocurrency market data using **CoinGecko API**, **Snowflake**, **dbt**, **Apache Airflow**, and **Power BI**.

---

## ğŸ”§ Tech Stack

- **Data Extraction**: Python (CoinGecko API)
- **Data Loading**: Snowflake (via Python connector)
- **Data Transformation**: dbt (data models & staging)
- **Orchestration**: Apache Airflow (Docker-based setup)
- **Visualization**: Power BI (ODBC connector to Snowflake)

---

## ğŸ“¦ Project Structure

financial_data_pipeline/
â”œâ”€â”€ airflow/
â”‚ â”œâ”€â”€ dags/
â”‚ â”‚ â””â”€â”€ elt_dag.py # Airflow DAG for ELT
â”œâ”€â”€ dbt_project/ # dbt transformations
â”œâ”€â”€ etl_scripts/
â”‚ â”œâ”€â”€ extract.py # Extract crypto data from API
â”‚ â””â”€â”€ load_to_snowflake.py # Load data into Snowflake
â”œâ”€â”€ data/raw/ # Raw data storage (CSV)
â”œâ”€â”€ docker-compose.yml # Airflow + Postgres setup
â””â”€â”€ README.md # Project documentation

---

## âš™ï¸ Workflow

1. **Extract**: Python script hits CoinGecko API to fetch:
   - 30-day historical market charts
   - Coin metadata
   - Global market statistics

2. **Load**: Cleaned CSVs are loaded into **Snowflake** tables.

3. **Transform**: dbt creates staging models and combined views.

4. **Schedule**: Airflow DAG automates the full pipeline daily.

5. **Visualize**: Power BI connects directly to Snowflake to present key KPIs and interactive dashboards.

---

## ğŸ“Š Dashboards

**Power BI Dashboards include:**

- **KPI Cards**:
  - Total Coins Tracked
  - Avg. Daily Volume (30d)
  - Max Price (30d)
  - Lowest Market Cap Coin

- **Charts**:
  - Line Chart: Price trends by month & coin
  - Bar Chart: Volume_24h comparison across coins
  - Pie Chart: Market cap share by coin
  - Area Chart: Volume trend across time
  - Radar Chart: Developer & Community score comparison

---

## ğŸ”‘ Credentials

Make sure to set up your Snowflake credentials via environment variables or `.env` file.

```env
SNOWFLAKE_USER=
SNOWFLAKE_PASSWORD=
SNOWFLAKE_ACCOUNT=
SNOWFLAKE_DATABASE=FINANCIAL_DB
SNOWFLAKE_SCHEMA=RAW
SNOWFLAKE_WAREHOUSE=NEWCOMPUTE_WH
